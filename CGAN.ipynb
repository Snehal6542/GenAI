{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4b75c7e-fd9a-40b3-9171-9be8daef7642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34e9b789-bb41-4ada-ae4c-06358accfc5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in c:\\users\\sneha\\appdata\\roaming\\python\\python312\\site-packages (2.6.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\sneha\\appdata\\roaming\\python\\python312\\site-packages (0.21.0)\n",
      "Requirement already satisfied: matplotlib in c:\\programdata\\anaconda3\\lib\\site-packages (3.9.2)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\sneha\\appdata\\roaming\\python\\python312\\site-packages (4.11.0.86)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: networkx in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\sneha\\appdata\\roaming\\python\\python312\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision matplotlib numpy opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c1c6e52-9684-45b6-9d97-e2ee441dae27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e509872e-1a00-4672-a585-1003c8d389fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShapeDataset(Dataset):\n",
    "    def __init__(self, num_samples=1000, img_size=28):\n",
    "        self.img_size = img_size\n",
    "        self.num_samples = num_samples\n",
    "        self.shapes = ['circle', 'square', 'triangle']\n",
    "        self.data = []\n",
    "        self.labels = []\n",
    "        self._generate_dataset()\n",
    "\n",
    "    def _generate_shape(self, shape):\n",
    "        img = np.zeros((self.img_size, self.img_size), dtype=np.uint8)\n",
    "        if shape == \"circle\":\n",
    "            cv2.circle(img, (14, 14), 7, 255, -1)\n",
    "        elif shape == \"square\":\n",
    "            cv2.rectangle(img, (7, 7), (21, 21), 255, -1)\n",
    "        elif shape == \"triangle\":\n",
    "            pts = np.array([[14, 6], [6, 22], [22, 22]], np.int32)\n",
    "            cv2.drawContours(img, [pts], 0, 255, -1)\n",
    "        return img\n",
    "\n",
    "    def _generate_dataset(self):\n",
    "        for _ in range(self.num_samples):\n",
    "            shape = random.choice(self.shapes)\n",
    "            img = self._generate_shape(shape)\n",
    "            label = self.shapes.index(shape)\n",
    "            self.data.append(img)\n",
    "            self.labels.append(label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.data[idx]\n",
    "        img = img.astype(np.float32) / 255.0\n",
    "        img = torch.tensor(img).view(-1)\n",
    "        label = torch.tensor(self.labels[idx])\n",
    "        return img, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "230cb171-c516-4ce7-a17f-2585214ee8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(labels, num_classes=3):\n",
    "    return torch.nn.functional.one_hot(labels, num_classes=num_classes).float()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28ea6e33-ee9c-4a98-9d5b-464b3a75d4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, noise_dim=100, label_dim=3, img_dim=784):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(noise_dim + label_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, img_dim),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, noise, labels):\n",
    "        x = torch.cat([noise, labels], dim=1)\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, img_dim=784, label_dim=3):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(img_dim + label_dim, 128),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(128, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, img, labels):\n",
    "        x = torch.cat([img, labels], dim=1)\n",
    "        return self.model(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1843e03-7741-4a9d-bc66-21f86199c362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100] D_loss: 1.0205 G_loss: 0.7795\n",
      "Epoch [20/100] D_loss: 0.5236 G_loss: 1.5170\n",
      "Epoch [30/100] D_loss: 0.6590 G_loss: 1.1509\n",
      "Epoch [40/100] D_loss: 1.1093 G_loss: 0.7199\n",
      "Epoch [50/100] D_loss: 0.8369 G_loss: 1.0521\n",
      "Epoch [60/100] D_loss: 0.8204 G_loss: 1.1396\n",
      "Epoch [70/100] D_loss: 0.8846 G_loss: 0.9703\n",
      "Epoch [80/100] D_loss: 0.8517 G_loss: 1.0540\n",
      "Epoch [90/100] D_loss: 0.5439 G_loss: 1.4744\n",
      "Epoch [100/100] D_loss: 0.6320 G_loss: 1.3770\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "epochs = 100\n",
    "batch_size = 64\n",
    "noise_dim = 100\n",
    "lr = 0.0002\n",
    "\n",
    "# Data\n",
    "dataset = ShapeDataset()\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Models\n",
    "generator = Generator(noise_dim=noise_dim)\n",
    "discriminator = Discriminator()\n",
    "\n",
    "# Loss and Optimizers\n",
    "criterion = nn.BCELoss()\n",
    "optimizer_G = optim.Adam(generator.parameters(), lr=lr)\n",
    "optimizer_D = optim.Adam(discriminator.parameters(), lr=lr)\n",
    "\n",
    "# Training Loop\n",
    "for epoch in range(epochs):\n",
    "    for real_imgs, labels in dataloader:\n",
    "        batch_size = real_imgs.size(0)\n",
    "        real_labels = torch.ones(batch_size, 1)\n",
    "        fake_labels = torch.zeros(batch_size, 1)\n",
    "\n",
    "        # One-hot encode labels\n",
    "        labels_onehot = one_hot(labels)\n",
    "\n",
    "        # Train Discriminator\n",
    "        z = torch.randn(batch_size, noise_dim)\n",
    "        fake_imgs = generator(z, labels_onehot).detach()\n",
    "\n",
    "        d_real = discriminator(real_imgs, labels_onehot)\n",
    "        d_fake = discriminator(fake_imgs, labels_onehot)\n",
    "\n",
    "        d_loss = criterion(d_real, real_labels) + criterion(d_fake, fake_labels)\n",
    "\n",
    "        optimizer_D.zero_grad()\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        # Train Generator\n",
    "        z = torch.randn(batch_size, noise_dim)\n",
    "        fake_imgs = generator(z, labels_onehot)\n",
    "        d_fake = discriminator(fake_imgs, labels_onehot)\n",
    "        g_loss = criterion(d_fake, real_labels)\n",
    "\n",
    "        optimizer_G.zero_grad()\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}] D_loss: {d_loss.item():.4f} G_loss: {g_loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5cb0a8-4fd6-47ad-9993-c02bb5c47b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_plot(label_text):\n",
    "    label_dict = {'circle': 0, 'square': 1, 'triangle': 2}\n",
    "    label = torch.tensor([label_dict[label_text]])\n",
    "    label_onehot = one_hot(label)\n",
    "    noise = torch.randn(1, noise_dim)\n",
    "    with torch.no_grad():\n",
    "        fake_img = generator(noise, label_onehot).view(28, 28)\n",
    "    plt.imshow(fake_img.cpu(), cmap='gray')\n",
    "    plt.title(f'Generated: {label_text}')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "generate_and_plot(\"circle\")\n",
    "generate_and_plot(\"square\")\n",
    "generate_and_plot(\"triangle\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1a8884b-304f-4013-aacd-1664bcef8fce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x300 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def draw_shape(label, size=(28, 28)):\n",
    "    img = Image.new('L', size, color=0)\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    if label == \"circle\":\n",
    "        draw.ellipse((6, 6, 22, 22), fill=255)\n",
    "    elif label == \"square\":\n",
    "        draw.rectangle((6, 6, 22, 22), fill=255)\n",
    "    elif label == \"triangle\":\n",
    "        draw.polygon([(14, 4), (4, 24), (24, 24)], fill=255)\n",
    "    return img\n",
    "\n",
    "# Just draw and display one of each shape (no saving to files)\n",
    "labels = ['circle', 'square', 'triangle']\n",
    "images = [draw_shape(label) for label in labels]\n",
    "\n",
    "# Display safely\n",
    "fig, axes = plt.subplots(1, 3, figsize=(8, 3))\n",
    "for ax, img, label in zip(axes, images, labels):\n",
    "    ax.imshow(np.array(img), cmap='gray')\n",
    "    ax.set_title(label)\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db5a40c-c632-4228-a1b1-eeca8ef9f06f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
