{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18bc530b-a555-49de-8f39-9e268a5de342",
   "metadata": {},
   "source": [
    " 1. Installing Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "860ccd8d-5169-41a3-aaf9-ddab338851f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers torch --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3188a3be-bc93-4eab-92a1-15fff2e790f9",
   "metadata": {},
   "source": [
    " 2. Importing the tokenizer and model loader from transformers, along with PyTorch and NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a10f5bd-b7c0-460a-9946-3b3c61c9b1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdedb879-ee71-4c19-9eae-8de8f0fa03eb",
   "metadata": {},
   "source": [
    " 3. I am choosing the distilbert-base-uncased model — a lightweight and fast BERT variant — and load both the tokenizer and the model. Also suppress the symlink warning that appears on Windows systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e58d978-4180-4053-884b-1eb5908df93d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded model and tokenizer: distilbert-base-uncased\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"HF_HUB_DISABLE_SYMLINKS_WARNING\"] = \"1\"\n",
    "\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "print(f\"Successfully loaded model and tokenizer: {model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e478138e-8529-4d22-be73-bd9d8eaefda4",
   "metadata": {},
   "source": [
    " 4. Defining descriptive, natural-language captions for flowers. These simulate real captions a user might input for text-to-image generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de84884e-7398-4c85-b7f0-521232afb44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_descriptions = [\n",
    "    \"The water lily is floating gently on the pond with large green leaves.\",\n",
    "    \"A desert rose with thick succulent stems and vibrant pink petals.\",\n",
    "    \"Gazania flowers bloom with bright orange and yellow striped petals.\",\n",
    "    \"A wild pansy with a mix of purple, yellow, and white petals.\",\n",
    "    \"An oxeye daisy with white petals and a sunny yellow center in a meadow.\",\n",
    "    \"The columbine flower has a unique bell shape with purple and white colors.\",\n",
    "    \"A tall sword lily with elegant, vibrant red flowers blooming upward.\",\n",
    "    \"A bright orange dahlia with multiple layered petals and a dark center.\",\n",
    "    \"A barbeton daisy showing vivid pink petals with a golden center.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fd7bce-a74f-4aef-b3fa-50299c076d80",
   "metadata": {},
   "source": [
    " 5. Tokenizing the flower descriptions using the tokenizer. Padding and truncation are applied to ensure consistent sequence length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "604e3d13-124d-44f8-b015-edc772bc7abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs shape: torch.Size([9, 18])\n",
      "Attention Mask shape: torch.Size([9, 18])\n"
     ]
    }
   ],
   "source": [
    "encoded_inputs = tokenizer(\n",
    "    text_descriptions,\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "input_ids = encoded_inputs[\"input_ids\"]\n",
    "attention_mask = encoded_inputs[\"attention_mask\"]\n",
    "\n",
    "print(\"Input IDs shape:\", input_ids.shape)\n",
    "print(\"Attention Mask shape:\", attention_mask.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831fe10d-95c1-4976-bda3-c7a132c2d78a",
   "metadata": {},
   "source": [
    " 6. Passing the tokenized input into the model to get the last hidden states — the contextual embeddings for each token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70d85a5b-1aa8-4562-882c-609cd07393e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last hidden states shape: torch.Size([9, 18, 768])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "last_hidden_states = outputs.last_hidden_state\n",
    "print(\"Last hidden states shape:\", last_hidden_states.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1122be63-5b37-4486-b63a-4d92c7576801",
   "metadata": {},
   "source": [
    " 7. To convert variable-length token embeddings into fixed-size sentence embeddings, performing mean pooling, using the attention mask to exclude padding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c149577-f386-453a-bec0-cceb96624190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence embeddings shape: torch.Size([9, 768])\n"
     ]
    }
   ],
   "source": [
    "def mean_pooling(hidden_states, attention_mask):\n",
    "    mask_expanded = attention_mask.unsqueeze(-1).expand(hidden_states.size()).float()\n",
    "    sum_embeddings = torch.sum(hidden_states * mask_expanded, dim=1)\n",
    "    sum_mask = torch.clamp(mask_expanded.sum(dim=1), min=1e-9)\n",
    "    return sum_embeddings / sum_mask\n",
    "\n",
    "sentence_embeddings = mean_pooling(last_hidden_states, attention_mask)\n",
    "print(\"Sentence embeddings shape:\", sentence_embeddings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8f3348-95e5-4ef1-bb96-41bd6be62971",
   "metadata": {},
   "source": [
    " 8. The final pooled sentence embeddings are converted into a NumPy array for compatibility with machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "786792fd-19ad-47b5-9750-d03283506504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample vector for 'Water Lily':\n",
      "[-0.20325074  0.05302349 -0.00336746  0.2590729   0.30261055 -0.33806202\n",
      " -0.35584727  0.5285601  -0.16368869  0.00060811]\n"
     ]
    }
   ],
   "source": [
    "sentence_embeddings_np = sentence_embeddings.cpu().numpy()\n",
    "print(\"Sample vector for 'Water Lily':\")\n",
    "print(sentence_embeddings_np[0][:10])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
